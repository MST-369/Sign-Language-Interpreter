{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c93a8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "befc7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This Class is created for video\n",
    "class yolo_model():\n",
    "    def __init__(self,onnx,yamlfile):\n",
    "        with open(yamlfile,mode='r') as f:\n",
    "            dy = yaml.load(f, Loader=SafeLoader)\n",
    "        self.L=dy['names']\n",
    "        self.yolo=cv2.dnn.readNetFromONNX(onnx)\n",
    "        self.yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "                                    \n",
    "    def Preds(self, im, condition=''):\n",
    "        m,n,d = im.shape\n",
    "        mc = max(m,n)\n",
    "        ni = np.zeros((mc,mc,3),dtype=np.uint8)\n",
    "        ni[:m,:n]=im\n",
    "        input_wh_yolo=640\n",
    "        blob = cv2.dnn.blobFromImage(ni,1/255,(input_wh_yolo,input_wh_yolo),swapRB=True,crop=False)\n",
    "        yolo.setInput(blob)\n",
    "        preds = yolo.forward()\n",
    "        \n",
    "        dect = preds[0]\n",
    "        bnds = []\n",
    "        confs= []\n",
    "        cls = []\n",
    "\n",
    "        im_w,im_h = ni.shape[:2]\n",
    "        xf = im_w/input_wh_yolo\n",
    "        yf = im_h/input_wh_yolo\n",
    "        \n",
    "        if len(dect):\n",
    "            for i in range(len(dect)):\n",
    "                row = dect[i]\n",
    "                conf = row[4]\n",
    "                if conf > 0.4:\n",
    "                    cs = row[5:].max()\n",
    "                    id = row[5:].argmax()\n",
    "                    if cs > 0.25:\n",
    "                        cx, cy, w, h = row[0:4]\n",
    "                        l = int((cx - 0.5*w)*xf)\n",
    "                        t = int((cy - 0.5*h)*yf)\n",
    "                        w = int(w*xf)\n",
    "                        h = int(h*yf)\n",
    "                        bnd = np.array([l,t,w,h])\n",
    "                        confs.append(conf)\n",
    "                        bnds.append(bnd)\n",
    "                        cls.append(id)\n",
    "\n",
    "            b_np = np.array(bnds).tolist()\n",
    "            confs_np = np.array(confs).tolist()\n",
    "\n",
    "            ind = cv2.dnn.NMSBoxes(b_np,confs_np,0.25,0.45)\n",
    "            if len(ind)==0:\n",
    "                return im,[]\n",
    "            k=[]\n",
    "            ind = ind.flatten()\n",
    "            for i in ind:\n",
    "                x,y,w,h = b_np[i]\n",
    "                bb_conf = round(confs_np[i],2)\n",
    "                cn = L[cls[i]-1]\n",
    "                k.append(cn)\n",
    "                txt = f'{cn}: {bb_conf}%'\n",
    "                cv2.rectangle(ni,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                cv2.rectangle(ni,(x,y-30),(x+w,y),(255,255,255),-1)\n",
    "                cv2.putText(ni,txt,(x,y-10),cv2.FONT_HERSHEY_PLAIN,0.7,(0,0,0),1)\n",
    "        if condition=='Testing':\n",
    "            return k\n",
    "                                    \n",
    "        return ni,cn\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b624d2",
   "metadata": {},
   "source": [
    "# Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "37901fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KOTA SRI SURYA TEJA\\AppData\\Local\\Temp\\ipykernel_18756\\1628575337.py:15: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if len(c)>0 and L[k-1] in c:\n"
     ]
    }
   ],
   "source": [
    "model='C:/Users/KOTA SRI SURYA TEJA/Desktop/MLDL dataset/American-sign-language.v2i.voc/Trained_model/Model13/weights/best.onnx'\n",
    "path='C:/Users/KOTA SRI SURYA TEJA/Desktop/MLDL dataset/data.yaml'\n",
    "Y=yolo_model(model,path)\n",
    "target = 'C:/Users/KOTA SRI SURYA TEJA/Desktop/MLDL dataset/Test_output.csv'\n",
    "tar = 'C:/Users/KOTA SRI SURYA TEJA/Desktop/MLDL dataset/American-sign-language.v2i.voc/Data/test_images' \n",
    "t=0\n",
    "m=0\n",
    "test_data=pd.read_csv(target)\n",
    "c1=0\n",
    "for i in test_data['filename'].unique():\n",
    "    im=cv2.imread(os.path.join(tar,i[:-4]+'.jpg'))\n",
    "    c=Y.Preds(im,'Testing')\n",
    "    j=test_data[test_data['filename']==i]['sign']\n",
    "    for k in j:\n",
    "        if len(c)>0 and L[k-1] in c:\n",
    "            t+=1\n",
    "        else:\n",
    "            m+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "838126d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.983132530120482\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy: {t/(t+m)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0c148",
   "metadata": {},
   "source": [
    "# Follow below code to test a video and get the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "98ce0d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='C:/Users/KOTA SRI SURYA TEJA/Desktop/MLDL dataset/American-sign-language.v2i.voc/Trained_model/Model13/weights/best.onnx'\n",
    "path='C:/Users/KOTA SRI SURYA TEJA/Desktop/MLDL dataset/data.yaml'\n",
    "c=yolo_model(model,path)\n",
    "words=[]\n",
    "video=cv2.VideoCapture('C:/Users/KOTA SRI SURYA TEJA/Pictures/Camera Roll/WIN_20240430_19_36_36_Pro.mp4')\n",
    "video.set(cv2.CAP_PROP_FPS, 5)\n",
    "while 1:\n",
    "    f, shot = video.read()\n",
    "    if f==False:\n",
    "        break\n",
    "    n_i,w = c.Preds(shot)\n",
    "    words.append(w)\n",
    "    cv2.imshow('video',n_i)\n",
    "    if cv2.waitKey(1)==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d9ad29",
   "metadata": {},
   "source": [
    "# Finding the Labels from the Image or video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4c73418d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello']\n"
     ]
    }
   ],
   "source": [
    "cn=[]\n",
    "for i in words:\n",
    "    if i not in cn and i!=[]:\n",
    "        cn.append(i)\n",
    "        \n",
    "print(cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bb7813",
   "metadata": {},
   "source": [
    "# Labels to Generate the Text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a9258561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ContentBlock(text=\"Hello there! It's wonderful to meet you.\", type='text')]\n"
     ]
    }
   ],
   "source": [
    "key = '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'\n",
    "import anthropic\n",
    "  \n",
    "  # create a client instance\n",
    "client = anthropic.Anthropic(\n",
    "      api_key=key,\n",
    ")\n",
    "\n",
    "  # create the prompt and call the API\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    system=\"Respond in short and clear sentences.\",\n",
    "    messages=[\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f'generate 1 short sentence on {cn} for blind person [just return the text like a person would say]'\n",
    "          }\n",
    "      ]\n",
    "  )\n",
    "\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a51ef1f",
   "metadata": {},
   "source": [
    "# Audio from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c9f167f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3 as sp\n",
    "e= sp.init()\n",
    "e.say(message.content[0].text)\n",
    "e.runAndWait()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
